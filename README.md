# Unified Test Plan Template for Stored Procedures

**Document Title:** Unified Test Plan Template for Stored Procedures
**Version:** 1.0
**Date:** 26th August 2025
**Author:** ElancoGPT

---

### 1. Objective

To ensure the `[Stored Procedure Name]` stored procedure functions correctly, reliably, and efficiently according to its defined business logic and technical specifications. This includes verifying data integrity, accuracy of transformations, and proper handling of various data states.

### 2. Scope

*   **In-Scope:**
    *   **Functional Correctness:** Verification that the stored procedure performs its intended data manipulation (Insert, Update, Delete, Select, Transform) accurately.
    *   **Data Integrity:** Ensuring that data remains consistent and adheres to defined constraints (e.g., referential integrity, data types) after execution.
    *   **Edge Case Handling:** Testing the SP's behavior with boundary conditions (e.g., empty inputs, null values, max length strings, zero/negative numbers where not expected).
    *   **Error Handling:** If applicable, validating that the SP gracefully handles expected errors and logs information appropriately (e.g., using `TRY...CATCH`).
    *   **Logging/Auditing:** Verifying that any audit trails, logs, or status updates generated by the SP are accurate and complete.
    *   **Performance (Basic):** A basic check to ensure the SP completes within an acceptable timeframe for small to medium datasets. (For detailed performance, a separate performance test phase is recommended).
*   **Out-of-Scope:**
    *   Performance testing under extreme load or concurrent execution (unless explicitly required and added to the scope for a specific SP).
    *   Security vulnerabilities (e.g., SQL Injection, permissions).
    *   Testing of upstream or downstream processes unless directly impacted by the SP's output.

### 3. Prerequisites

*   **Database Environment:** Access to a dedicated testing environment (e.g., Development, QA, Staging) that mirrors the production environment as closely as possible.
*   **Database Access:** Necessary permissions to execute the stored procedure and query/manipulate data in all relevant source, target, and logging tables.
*   **Schema & Tables:** All required tables (source, target, lookup, logging) must exist with correct schema definitions (columns, data types, constraints).
*   **Dependent Objects:** Any other stored procedures, functions, views, or triggers that `[Stored Procedure Name]` depends on must be deployed and functional.
*   **Parent Data:** If the SP relies on data from parent tables (e.g., foreign key relationships), ensure those parent tables are pre-populated as needed.

### 4. Test Data Setup Strategy

For each test case, the general approach involves:

1.  **Clear Relevant Tables:** Cleanse target tables and, if necessary, source tables to ensure a controlled starting state.
    *   `TRUNCATE TABLE [TargetTable1];`
    *   `DELETE FROM [SourceTable1];` (if `TRUNCATE` is not suitable due to foreign keys or logging)
    *   `TRUNCATE TABLE [LoggingTable];` (if applicable)
2.  **Populate Dependent Data:** Insert necessary data into any tables that `[Stored Procedure Name]` joins with or references (e.g., lookup tables, parent entities).
    *   `INSERT INTO [DependencyTable] (Col1, Col2) VALUES (...);`
3.  **Populate Source Data:** Insert specific data into the source table(s) that will be processed by the stored procedure, representing the scenario under test (e.g., new records, updated records, records to be deleted, invalid records).
    *   `INSERT INTO [SourceTable] (Col1, Col2, ...) VALUES (...);`
4.  **Capture Before State:** Record the data in all relevant tables (*before* executing the SP) to compare with the "after" state.
    *   `SELECT * FROM [TargetTable1];`
    *   `SELECT * FROM [SourceTable1];`
5.  **Execute the SP:**
    *   `EXEC [Schema].[Stored Procedure Name] [Parameter1], [Parameter2], ...;`
6.  **Capture After State:** Record the data in all relevant tables (*after* executing the SP).
    *   `SELECT * FROM [TargetTable1];`
    *   `SELECT * FROM [SourceTable1];`
    *   `SELECT * FROM [LoggingTable];`
7.  **Verify Results:** Compare the "Before" and "After" states against the expected outcome for the specific test case.

**Helper SQL Snippets (Generic Examples):**

```sql
-- For clearing tables
TRUNCATE TABLE [YourTargetTable];
TRUNCATE TABLE [YourLoggingTable];
DELETE FROM [YourSourceTable]; -- Use DELETE if TRUNCATE is not possible (e.g., foreign keys or transaction log)

-- For setting up source data (customize columns and values)
INSERT INTO [YourSourceTable] (ColumnA, ColumnB, CreatedDate)
VALUES ('Value1', 100, GETDATE());

-- For executing the SP (customize parameters)
EXEC [dbo].[YourStoredProcedureName] @Param1 = 'TestValue', @Param2 = 123;

-- For verifying data
SELECT * FROM [YourTargetTable];
SELECT * FROM [YourSourceTable];
SELECT * FROM [YourLoggingTable];
```

### 5. Test Cases

#### 5.1. Functional / Positive Scenarios

*   **Test Case 5.1.1: Initial Load / Insert New Records**
    *   **Description:** Verify that the SP correctly inserts new records into the target table(s) when no matching records exist.
    *   **Setup:** Source tables contain new records. Target tables are empty or contain no matching records.
    *   **Expected Result:** New records are inserted into the target table(s) with correct values.
*   **Test Case 5.1.2: Update Existing Records**
    *   **Description:** Verify that the SP correctly updates existing records in the target table(s) when changes are detected in the source.
    *   **Setup:** Target tables contain existing records. Source tables contain matching records with updated values.
    *   **Expected Result:** Existing records in the target table(s) are updated with the new values from the source.
*   **Test Case 5.1.3: Delete Records**
    *   **Description:** Verify that the SP correctly deletes records from the target table(s) based on specific criteria (e.g., `IsDeletedFlag`, records missing from source).
    *   **Setup:** Target tables contain records to be deleted. Source tables reflect the deletion condition.
    *   **Expected Result:** Specified records are deleted from the target table(s).
*   **Test Case 5.1.4: Mixed Operations (Insert, Update, Delete)**
    *   **Description:** Test the SP's ability to handle a combination of new, updated, and deleted records in a single execution.
    *   **Setup:** Source data includes records for insertion, updating, and deletion. Target data reflects a mix of existing and non-existing records.
    *   **Expected Result:** All operations (insert, update, delete) are performed correctly as per the source data.
*   **Test Case 5.1.5: Idempotency / No Changes**
    *   **Description:** Verify that running the SP when no changes are present in the source data results in no (or minimal, expected) modifications to the target or logging tables.
    *   **Setup:** Source and target tables are fully synchronized with no pending changes.
    *   **Expected Result:** No new inserts, updates, or deletes occur in the target tables. Logging tables show no new relevant change entries.

#### 5.2. Edge Cases / Negative Scenarios

*   **Test Case 5.2.1: Empty Source Data**
    *   **Description:** Test the SP's behavior when source tables contain no data.
    *   **Setup:** Source tables are empty. Target tables may or may not contain data.
    *   **Expected Result:** The SP completes without error. No new records are inserted. Existing records in target are handled as per deletion logic (if any).
*   **Test Case 5.2.2: Null / Invalid Input Parameters** (if SP accepts parameters)
    *   **Description:** Test the SP with `NULL` or invalid values for its input parameters.
    *   **Setup:** Call the SP with `@Param1 = NULL`, or `@Param1 = 'InvalidString'` (if expecting numeric), or values exceeding data type limits.
    *   **Expected Result:**
        *   If `NULL` is valid, SP processes correctly.
        *   If `NULL` is invalid, SP should raise an appropriate error or handle gracefully.
        *   Invalid data type input should result in a casting error or specific error handling.
*   **Test Case 5.2.3: Duplicate Source Data** (if the SP should handle or prevent duplicates)
    *   **Description:** Verify how the SP handles duplicate records in the source data that could lead to primary key violations or incorrect data.
    *   **Setup:** Source table contains records that, if processed, would violate unique constraints in the target table.
    *   **Expected Result:**
        *   If duplicates should be ignored: Only one instance is processed.
        *   If duplicates should error: SP fails with a primary key violation or similar error.
        *   If duplicates are expected and handled (e.g., by updating existing): SP updates the existing record.
*   **Test Case 5.2.4: Referential Integrity Violations** (if target tables have FKs and SP inserts/updates data that violates them)
    *   **Description:** Test if the SP attempts to insert or update records that would violate referential integrity constraints in the target database.
    *   **Setup:** Source data contains records referencing non-existent parent records in the target system.
    *   **Expected Result:** The SP should either fail with a foreign key violation error or handle the records gracefully (e.g., skip, log, or insert with NULL FK if allowed).

#### 5.3. Specific Logic Scenarios (Customize for each SP)

*   **Test Case 5.3.x: [Specific Business Rule 1]**
    *   **Description:** Test a unique calculation, transformation, or conditional logic within the SP.
    *   **Setup:** Data specifically designed to trigger `[Specific Business Rule 1]`.
    *   **Expected Result:** Output reflects correct application of `[Specific Business Rule 1]`.
*   **Test Case 5.3.y: [Specific Business Rule 2]**
    *   **Description:** Test another unique aspect of the SP's logic (e.g., status updates, date calculations, complex joins).
    *   **Setup:** Data specifically designed to trigger `[Specific Business Rule 2]`.
    *   **Expected Result:** Output reflects correct application of `[Specific Business Rule 2]`.
*   *(Add as many as needed for the specific SP, providing detailed descriptions, setup instructions, and expected results.)*

### 6. Test Execution

1.  **Preparation:** Ensure the test environment is ready and all prerequisites are met.
2.  **Iterate Test Cases:** For each test case defined in Section 5:
    *   Perform the "Test Data Setup" steps.
    *   Execute the `[Stored Procedure Name]`.
    *   Perform "Verification" steps.
    *   Record the outcome (Pass/Fail) and any observations in a test log or report.
3.  **Documentation:** Keep detailed records of:
    *   Test case ID and description.
    *   Input data used.
    *   Expected results.
    *   Actual results.
    *   Pass/Fail status.
    *   Any errors, warnings, or unexpected behaviors.
    *   Date and time of execution.
    *   Tester's name.

### 7. Verification

*   **Row Counts:** Compare the number of rows in source, target, and logging tables before and after execution.
    *   `SELECT COUNT(*) FROM [TableName];`
*   **Data Accuracy:**
    *   Use `SELECT` statements to inspect specific records in target tables, ensuring values match transformed source data.
    *   For complex comparisons, use `EXCEPT`, `LEFT JOIN`, or `CHECKSUM` to identify discrepancies between expected and actual data.
        ```sql
        -- Example for updates: find rows in target that don't match source after update
        SELECT T.*
        FROM [TargetTable] T
        LEFT JOIN [SourceTable] S ON T.PrimaryKey = S.PrimaryKey
        WHERE T.ColumnA <> S.ColumnA OR T.ColumnB <> S.ColumnB; -- Or use a HashCode comparison if available

        -- Example for inserts: check if all source records are in target
        SELECT S.*
        FROM [SourceTable] S
        LEFT JOIN [TargetTable] T ON S.PrimaryKey = T.PrimaryKey
        WHERE T.PrimaryKey IS NULL; -- These should be the newly inserted records
        ```
*   **Logging/Auditing:** Verify entries in logging tables (`[LoggingTable]`) for correctness of `ChangeType`, `RecordCount`, `OldValue`, `NewValue`, `Timestamp`, etc.
*   **Error Messages:** If an error scenario is tested, verify that the correct error message is raised (if applicable) or logged.
*   **Performance (Qualitative):** Observe execution time. For slow-running SPs, further investigation/optimization may be required.

### 8. Rollback / Cleanup Strategy

*   **Transactional Testing:** For critical or complex SPs, wrap the execution in a `BEGIN TRAN...ROLLBACK TRAN` block to revert changes after verification and maintain a clean test state for the next run.
    ```sql
    BEGIN TRAN;
    EXEC [dbo].[YourStoredProcedureName] @Param1 = 'TestValue';
    -- Verification SELECTs here
    ROLLBACK TRAN; -- Or COMMIT TRAN; if you want to keep the changes
    ```
*   **Pre-Test Cleanup:** As outlined in Section 4, use `TRUNCATE TABLE` or `DELETE FROM` statements at the beginning of each test case setup to ensure test independence.
*   **Post-Test Cleanup:** If `ROLLBACK TRAN` is not used, ensure that all test data is cleaned up from the environment at the end of a testing cycle to avoid interference with other tests or environments.

---

**How to use this template:**

1.  **Replace Placeholders:** Go through the document and replace `[Stored Procedure Name]`, `[TargetTable]`, `[SourceTable]`, `[LoggingTable]`, `[ParameterX]`, and similar placeholders with the actual names relevant to the stored procedure you are testing.
2.  **Customize Sections:**
    *   **Objective:** Tailor the objective slightly to reflect the specific purpose of the SP.
    *   **Prerequisites:** Add any unique setup requirements for this specific SP.
    *   **Test Data Setup:** Provide concrete examples of `INSERT` statements with realistic data for your tables.
    *   **Test Cases:** The "Functional" and "Edge Cases" are largely generic. The "Specific Logic Scenarios" section is where you *must* add test cases unique to the stored procedure's business rules and transformations.
3.  **Review and Iterate:** Once filled out, review the plan with your team members to ensure all critical aspects of the SP are covered.
